[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "pymongo",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pymongo",
        "description": "pymongo",
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "UpdateOne",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "ZoneInfo",
        "importPath": "zoneinfo",
        "description": "zoneinfo",
        "isExtraImport": true,
        "detail": "zoneinfo",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "pytz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytz",
        "description": "pytz",
        "detail": "pytz",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "isExtraImport": true,
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "dumps",
        "importPath": "bson.json_util",
        "description": "bson.json_util",
        "isExtraImport": true,
        "detail": "bson.json_util",
        "documentation": {}
    },
    {
        "label": "dumps",
        "importPath": "bson.json_util",
        "description": "bson.json_util",
        "isExtraImport": true,
        "detail": "bson.json_util",
        "documentation": {}
    },
    {
        "label": "dumps",
        "importPath": "bson.json_util",
        "description": "bson.json_util",
        "isExtraImport": true,
        "detail": "bson.json_util",
        "documentation": {}
    },
    {
        "label": "contains_date",
        "kind": 2,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "def contains_date(line):\n    for i, pattern in enumerate(patterns):\n        if re.search(pattern, line):\n            return i\n    return None\ndef find_coordinates_partial_match(estacion):\n    estacion_words = set(estacion.split())\n    for station_name, coords in coordinates.items():\n        if estacion_words.intersection(station_name.split()):\n            return coords",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "find_coordinates_partial_match",
        "kind": 2,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "def find_coordinates_partial_match(estacion):\n    estacion_words = set(estacion.split())\n    for station_name, coords in coordinates.items():\n        if estacion_words.intersection(station_name.split()):\n            return coords\n    return None\ndef extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/meteo/\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "extractdata_meteo",
        "kind": 2,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "def extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/meteo/\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    madrid_tz = ZoneInfo(\"Europe/Madrid\")\n    files = os.listdir(df_meteo_path)\n    if not files:\n        logger.error(\"No traffic data files in folder available\")\n        return\n    logger.info(f'Number of files in directory: {len(files)}')",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\n# Retrieving and printting the log contents after data extraction",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "logs_directory",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "logs_directory = \"meteo/logs\"  # Replace with an absolute path if needed\nlog_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n# Checking if logs directory exists\nif not os.path.exists(logs_directory):\n    os.makedirs(logs_directory)\n# Setting up a specific logger for the application\nlogger = logging.getLogger(\"meteo_logger\")\nlogger.setLevel(logging.INFO)  # Set to DEBUG to capture all messages\n# file handler definition to write logs to file\nfile_handler = logging.FileHandler(log_file_path)",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "log_file_path",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "log_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n# Checking if logs directory exists\nif not os.path.exists(logs_directory):\n    os.makedirs(logs_directory)\n# Setting up a specific logger for the application\nlogger = logging.getLogger(\"meteo_logger\")\nlogger.setLevel(logging.INFO)  # Set to DEBUG to capture all messages\n# file handler definition to write logs to file\nfile_handler = logging.FileHandler(log_file_path)\nfile_handler.setLevel(logging.INFO)",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "logger = logging.getLogger(\"meteo_logger\")\nlogger.setLevel(logging.INFO)  # Set to DEBUG to capture all messages\n# file handler definition to write logs to file\nfile_handler = logging.FileHandler(log_file_path)\nfile_handler.setLevel(logging.INFO)\n# Creating stream handler to output logs to console\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n# Defining log format\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "file_handler = logging.FileHandler(log_file_path)\nfile_handler.setLevel(logging.INFO)\n# Creating stream handler to output logs to console\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n# Defining log format\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nconsole_handler.setFormatter(formatter)\n# Adding handlers to the logger",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "console_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n# Defining log format\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nconsole_handler.setFormatter(formatter)\n# Adding handlers to the logger\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)\n# Log a test message",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nconsole_handler.setFormatter(formatter)\n# Adding handlers to the logger\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)\n# Log a test message\nlogger.info(\"Starting the script\")\n# Defining date patterns to match different date formats\npatterns = [",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "patterns",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "patterns = [\n    r\"^\\d{4}-\\d{2}-\\d{2}\",    # YYYY-MM-DD\n    r\"^\\d{2}/\\d{2}/\\d{4}\",    # DD/MM/YYYY or MM/DD/YYYY\n    r\"^[A-Za-z]+\\s\\d{1,2},\\s\\d{4}\"  # Month Day, Year\n]\n# MongoDB Connection\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "db = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "coordinates",
        "kind": 5,
        "importPath": "meteo.extract_data_meteo",
        "description": "meteo.extract_data_meteo",
        "peekOfCode": "coordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],\n    \"València Port Moll Trans Ponent\": [39.459264, -0.323217],\n    \"Nazaret Met-2\": [39.448554, -0.333289],",
        "detail": "meteo.extract_data_meteo",
        "documentation": {}
    },
    {
        "label": "def_logs",
        "kind": 2,
        "importPath": "meteo.logs_config",
        "description": "meteo.logs_config",
        "peekOfCode": "def def_logs():\n    # Define the logs directory and log file path\n    logs_directory = \"logs\"\n    log_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n    # Ensure the logs directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up logging with an explicit FileHandler\n    try:\n        # Create a logger and set to DEBUG level to capture all messages",
        "detail": "meteo.logs_config",
        "documentation": {}
    },
    {
        "label": "extractdata_meteo",
        "kind": 2,
        "importPath": "meteo.mteo_test",
        "description": "meteo.mteo_test",
        "peekOfCode": "def extractdata_meteo():\n    path=\"/home/vagrant/Documents/bigdata/bigdata_project/meteo\"\n    #path = \"/home/vagrant/Documents/bigdata/data\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    id_estacion = 1\n    #########################\n    # Check if the traffic directory contains any files\n    if not os.listdir(df_meteo_path):\n        print(\"ERROR: No traffic data files in folder available\")",
        "detail": "meteo.mteo_test",
        "documentation": {}
    },
    {
        "label": "logs_path",
        "kind": 5,
        "importPath": "meteo.mteo_test",
        "description": "meteo.mteo_test",
        "peekOfCode": "logs_path = \"/home/vagrant/Documents/bigdata/bigdata_project/meteo\"\n#logging.basicConfig(file=f'{logs_path}/meteo_data.log',level=logging.INFO)\ncoordinates = {\n\"Av França\": [39.457504, -0.342689],\n\"Bulevard Sud\": [39.450378, -0.396313],\n\"Molí del Sol\": [39.481138, -0.408558],\n\"Pista de Silla\": [39.458060, -0.376653],\n\"Politècnic\": [39.479621, -0.337407],\n\"Centre\": [39.470718, -0.376384],\n\"Vivers\": [39.479488, -0.369550],",
        "detail": "meteo.mteo_test",
        "documentation": {}
    },
    {
        "label": "coordinates",
        "kind": 5,
        "importPath": "meteo.mteo_test",
        "description": "meteo.mteo_test",
        "peekOfCode": "coordinates = {\n\"Av França\": [39.457504, -0.342689],\n\"Bulevard Sud\": [39.450378, -0.396313],\n\"Molí del Sol\": [39.481138, -0.408558],\n\"Pista de Silla\": [39.458060, -0.376653],\n\"Politècnic\": [39.479621, -0.337407],\n\"Centre\": [39.470718, -0.376384],\n\"Vivers\": [39.479488, -0.369550],\n\"València Port Moll Trans Ponent\": [39.459264, -0.323217],\n\"Nazaret Met-2\": [39.448554, -0.333289],",
        "detail": "meteo.mteo_test",
        "documentation": {}
    },
    {
        "label": "patterns",
        "kind": 5,
        "importPath": "meteo.mteo_test",
        "description": "meteo.mteo_test",
        "peekOfCode": "patterns = [\n        r\"^\\d{4}-\\d{2}-\\d{2}\",    # YYYY-MM-DD\n        r\"^\\d{2}/\\d{2}/\\d{4}\",    # DD/MM/YYYY or MM/DD/YYYY\n        r\"^[A-Za-z]+\\s\\d{1,2},\\s\\d{4}\"  # Month Day, Year\n    ]\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef extractdata_meteo():\n    path=\"/home/vagrant/Documents/bigdata/bigdata_project/meteo\"\n    #path = \"/home/vagrant/Documents/bigdata/data\"",
        "detail": "meteo.mteo_test",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "meteo.mteo_test",
        "description": "meteo.mteo_test",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef extractdata_meteo():\n    path=\"/home/vagrant/Documents/bigdata/bigdata_project/meteo\"\n    #path = \"/home/vagrant/Documents/bigdata/data\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    id_estacion = 1\n    #########################\n    # Check if the traffic directory contains any files",
        "detail": "meteo.mteo_test",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "meteo.mteo_test",
        "description": "meteo.mteo_test",
        "peekOfCode": "db = client.bigdata\ndef extractdata_meteo():\n    path=\"/home/vagrant/Documents/bigdata/bigdata_project/meteo\"\n    #path = \"/home/vagrant/Documents/bigdata/data\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    id_estacion = 1\n    #########################\n    # Check if the traffic directory contains any files\n    if not os.listdir(df_meteo_path):",
        "detail": "meteo.mteo_test",
        "documentation": {}
    },
    {
        "label": "contains_date",
        "kind": 2,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "def contains_date(line):\n    for i, pattern in enumerate(patterns):\n        if re.search(pattern, line):\n            return i\n    return None\ndef find_coordinates_partial_match(estacion):\n    estacion_words = estacion.split()\n    for station_name, coords in coordinates.items():\n        if any(word in station_name for word in estacion_words):\n            return coords",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "find_coordinates_partial_match",
        "kind": 2,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "def find_coordinates_partial_match(estacion):\n    estacion_words = estacion.split()\n    for station_name, coords in coordinates.items():\n        if any(word in station_name for word in estacion_words):\n            return coords\n    return None\ndef extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/data/test\"\n    meteo_folder_name = 'meteo'\n    df_meteo_path = os.path.join(path, meteo_folder_name)",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "extractdata_meteo",
        "kind": 2,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "def extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/data/test\"\n    meteo_folder_name = 'meteo'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    madrid_tz = ZoneInfo(\"Europe/Madrid\")\n    files = os.listdir(df_meteo_path)\n    if not files:\n        print(\"ERROR: No traffic data files in folder available\")\n        return\n    print(\"ok meteo\")",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "patterns",
        "kind": 5,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "patterns = [\n    r\"^\\d{4}-\\d{2}-\\d{2}\",    # YYYY-MM-DD\n    r\"^\\d{2}/\\d{2}/\\d{4}\",    # DD/MM/YYYY or MM/DD/YYYY\n    r\"^[A-Za-z]+\\s\\d{1,2},\\s\\d{4}\"  # Month Day, Year\n]\n# MongoDB Connection\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "db = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "coordinates",
        "kind": 5,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "coordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],\n    \"València Port Moll Trans Ponent\": [39.459264, -0.323217],\n    \"Nazaret Met-2\": [39.448554, -0.333289],",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "document",
        "kind": 5,
        "importPath": "meteo.test2",
        "description": "meteo.test2",
        "peekOfCode": "document = db.meteo.find_one({\"id_estacion\": 2})\nprint(document)",
        "detail": "meteo.test2",
        "documentation": {}
    },
    {
        "label": "contains_date",
        "kind": 2,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "def contains_date(line):\n    for i, pattern in enumerate(patterns):\n        if re.search(pattern, line):\n            return i\n    return None\ndef find_coordinates_partial_match(estacion):\n    estacion_words = set(estacion.split())\n    for station_name, coords in coordinates.items():\n        if estacion_words.intersection(station_name.split()):\n            return coords",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "find_coordinates_partial_match",
        "kind": 2,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "def find_coordinates_partial_match(estacion):\n    estacion_words = set(estacion.split())\n    for station_name, coords in coordinates.items():\n        if estacion_words.intersection(station_name.split()):\n            return coords\n    return None\ndef extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/meteo/\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "extractdata_meteo",
        "kind": 2,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "def extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/meteo/\"\n    meteo_folder_name = 'estaciones_metereologicas'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    madrid_tz = ZoneInfo(\"Europe/Madrid\")\n    files = os.listdir(df_meteo_path)\n    if not files:\n        logger.error(\"No traffic data files in folder available\")\n        return\n    logger.info(f'Number of files in directory: {len(files)}')",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\n# Retrieve and print the log contents after data extraction",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "logs_directory",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "logs_directory = \"logs\"  # Replace with an absolute path if needed\nlog_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n# Ensure the logs directory exists\nif not os.path.exists(logs_directory):\n    os.makedirs(logs_directory)\n# Set up a specific logger for the application\nlogger = logging.getLogger(\"meteo_logger\")\nlogger.setLevel(logging.INFO)  # Set to DEBUG to capture all messages\n# Create file handler to write logs to file\nfile_handler = logging.FileHandler(log_file_path)",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "log_file_path",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "log_file_path = os.path.join(logs_directory, 'meteo_logs.log')\n# Ensure the logs directory exists\nif not os.path.exists(logs_directory):\n    os.makedirs(logs_directory)\n# Set up a specific logger for the application\nlogger = logging.getLogger(\"meteo_logger\")\nlogger.setLevel(logging.INFO)  # Set to DEBUG to capture all messages\n# Create file handler to write logs to file\nfile_handler = logging.FileHandler(log_file_path)\nfile_handler.setLevel(logging.INFO)",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "logger = logging.getLogger(\"meteo_logger\")\nlogger.setLevel(logging.INFO)  # Set to DEBUG to capture all messages\n# Create file handler to write logs to file\nfile_handler = logging.FileHandler(log_file_path)\nfile_handler.setLevel(logging.INFO)\n# Create stream handler to output logs to console\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n# Define log format\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "file_handler = logging.FileHandler(log_file_path)\nfile_handler.setLevel(logging.INFO)\n# Create stream handler to output logs to console\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n# Define log format\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nconsole_handler.setFormatter(formatter)\n# Add handlers to the logger",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "console_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n# Define log format\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nconsole_handler.setFormatter(formatter)\n# Add handlers to the logger\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)\n# Log a test message",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nconsole_handler.setFormatter(formatter)\n# Add handlers to the logger\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)\n# Log a test message\nlogger.info(\"Starting the script\")\n# Define date patterns to match different date formats\npatterns = [",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "patterns",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "patterns = [\n    r\"^\\d{4}-\\d{2}-\\d{2}\",    # YYYY-MM-DD\n    r\"^\\d{2}/\\d{2}/\\d{4}\",    # DD/MM/YYYY or MM/DD/YYYY\n    r\"^[A-Za-z]+\\s\\d{1,2},\\s\\d{4}\"  # Month Day, Year\n]\n# MongoDB Connection\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "db = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "coordinates",
        "kind": 5,
        "importPath": "meteo.test4",
        "description": "meteo.test4",
        "peekOfCode": "coordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],\n    \"València Port Moll Trans Ponent\": [39.459264, -0.323217],\n    \"Nazaret Met-2\": [39.448554, -0.333289],",
        "detail": "meteo.test4",
        "documentation": {}
    },
    {
        "label": "contains_date",
        "kind": 2,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "def contains_date(line):\n    \"\"\"Check if the line contains a date in specified formats.\"\"\"\n    for i, pattern in enumerate(patterns):\n        if re.search(pattern, line):\n            return i\n    return None\ndef find_coordinates_partial_match(estacion):\n    # Split the station name into words\n    estacion_words = estacion.split()\n    # Iterate through the coordinates dictionary to find partial matches",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "find_coordinates_partial_match",
        "kind": 2,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "def find_coordinates_partial_match(estacion):\n    # Split the station name into words\n    estacion_words = estacion.split()\n    # Iterate through the coordinates dictionary to find partial matches\n    for station_name, coords in coordinates.items():\n        # Check if any word in `estacion_words` is present in the `station_name`\n        if any(word in station_name for word in estacion_words):\n            return coords\n    # Return None if no match is found\n    return None",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "extractdata_meteo",
        "kind": 2,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "def extractdata_meteo():\n    path = \"/home/vagrant/Documents/bigdata/data/test\"\n    meteo_folder_name = 'meteo'\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    madrid_tz = ZoneInfo(\"Europe/Madrid\")\n    # Check if directory contains files\n    files = os.listdir(df_meteo_path)\n    if not files:\n        print(\"ERROR: No traffic data files in folder available\")\n        return  # Exit if no files found",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "patterns",
        "kind": 5,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "patterns = [\n    r\"^\\d{4}-\\d{2}-\\d{2}\",    # YYYY-MM-DD\n    r\"^\\d{2}/\\d{2}/\\d{4}\",    # DD/MM/YYYY or MM/DD/YYYY\n    r\"^[A-Za-z]+\\s\\d{1,2},\\s\\d{4}\"  # Month Day, Year\n]\n# MongoDB Connection\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "db = client.bigdata\n# Coordinates Dictionary\ncoordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "coordinates",
        "kind": 5,
        "importPath": "meteo.test_meteo",
        "description": "meteo.test_meteo",
        "peekOfCode": "coordinates = {\n    \"Av França\": [39.457504, -0.342689],\n    \"Bulevard Sud\": [39.450378, -0.396313],\n    \"Molí del Sol\": [39.481138, -0.408558],\n    \"Pista de Silla\": [39.458060, -0.376653],\n    \"Politècnic\": [39.479621, -0.337407],\n    \"Centre\": [39.470718, -0.376384],\n    \"Vivers\": [39.479488, -0.369550],\n    \"València Port Moll Trans Ponent\": [39.459264, -0.323217],\n    \"Nazaret Met-2\": [39.448554, -0.333289],",
        "detail": "meteo.test_meteo",
        "documentation": {}
    },
    {
        "label": "log_definition",
        "kind": 2,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "def log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger\")\n    logger.setLevel(logging.INFO)  # Use DEBUG for more verbose logging",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\ndef extractdata(logger):",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "def extractdata(logger):\n    # Setting the paths for your data directories\n    #path = \"data/test\"\n    path = \"/home/vagrant/Documents/bigdata/data\"\n    trafic_folder_name = 'trafico'\n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    # Checking if the traffic directory contains any files\n    if not os.path.exists(df_trafic_path):\n        logger.error(f\"ERROR: Path '{df_trafic_path}' does not exist.\")\n        return",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "def main():\n    # Initializing the logger to extract the logs from the operations\n    logger, logs_directory, _ = log_definition()\n    # Running data extraction\n    extractdata(logger)\n    # Retrieving logs\n    get_logs(logs_directory)\nmain()",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "#client",
        "kind": 5,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "trafico.extract_data",
        "description": "trafico.extract_data",
        "peekOfCode": "db = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger\")",
        "detail": "trafico.extract_data",
        "documentation": {}
    },
    {
        "label": "log_definition",
        "kind": 2,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "def log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log_test.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger_test\")\n    logger.setLevel(logging.INFO)  # Use DEBUG for more verbose logging",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\ndef extractdata(logger):",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "def extractdata(logger):\n    # Setting the paths for your data directories\n    #path = \"data/test\"\n    path = \"/home/vagrant/Documents/bigdata/data\" #/home/vagrant/Documents/bigdata/bigdata_project/data/test/trafico\n    trafic_folder_name = 'trafico'\n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    # Checking if the traffic directory contains any files\n    if not os.path.exists(df_trafic_path):\n        logger.error(f\"ERROR: Path '{df_trafic_path}' does not exist.\")\n        return",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "def main():\n    # Initializing the logger to extract the logs from the operations\n    logger, logs_directory, _ = log_definition()\n    # Running data extraction\n    extractdata(logger)\n    # Retrieving logs\n    get_logs(logs_directory)\nmain()",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "#client",
        "kind": 5,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log_test.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log_test.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "trafico.extract_data_test",
        "description": "trafico.extract_data_test",
        "peekOfCode": "db = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log_test.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger_test\")",
        "detail": "trafico.extract_data_test",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.test",
        "description": "trafico.test",
        "peekOfCode": "def extractdata():\n    # Set the paths for your data directories\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/data\"\n    trafic_folder_name = 'trafico'\n    meteo_folder_name = 'estaciones_metereologicos'\n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    grouped_data = {}  # Dictionary to store grouped data\n    # Check if the traffic directory contains any files\n    if not os.listdir(df_trafic_path):",
        "detail": "trafico.test",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.test2",
        "description": "trafico.test2",
        "peekOfCode": "def extractdata():\n    # Set the paths for your data directories\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/data\"\n    trafic_folder_name = 'trafico'\n    meteo_folder_name = 'estaciones_metereologicos'\n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    grouped_data = {}  # Dictionary to store grouped data\n    # Check if the traffic directory contains any files\n    if not os.listdir(df_trafic_path):",
        "detail": "trafico.test2",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.test3",
        "description": "trafico.test3",
        "peekOfCode": "def extractdata():\n    # Set the paths for your data directories\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/data\"\n    trafic_folder_name = 'trafico'\n    meteo_folder_name = 'estaciones_metereologicos'\n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    df_meteo_path = os.path.join(path, meteo_folder_name)\n    grouped_data = {}  # Dictionary to store grouped data\n    # Check if the traffic directory contains any files\n    if not os.listdir(df_trafic_path):",
        "detail": "trafico.test3",
        "documentation": {}
    },
    {
        "label": "log_definition",
        "kind": 2,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "def log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger\")\n    logger.setLevel(logging.INFO)  # Use DEBUG for more verbose logging",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\ndef extractdata(logger):",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "def extractdata(logger):\n    # Set the paths for your data directories\n    path = \"/home/vagrant/Documents/bigdata/data\"\n    trafic_folder_name = 'trafico'    \n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    # Check if the traffic directory contains any files\n    if not os.path.exists(df_trafic_path):\n        logger.error(f\"ERROR: Path '{df_trafic_path}' does not exist.\")\n        return\n    elif not os.listdir(df_trafic_path):",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "def main():\n    # Initialize the logger\n    logger, logs_directory, _ = log_definition()\n    # Run data extraction\n    extractdata(logger)\n    # Retrieve logs\n    get_logs(logs_directory)\nmain()",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "#client",
        "kind": 5,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up a specific logger for the application",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "trafico.test4",
        "description": "trafico.test4",
        "peekOfCode": "db = client.bigdata\ndef log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger\")",
        "detail": "trafico.test4",
        "documentation": {}
    },
    {
        "label": "process_file",
        "kind": 2,
        "importPath": "trafico.test5",
        "description": "trafico.test5",
        "peekOfCode": "def process_file(trafic_file_path):\n    \"\"\"Process a single traffic data file.\"\"\"\n    try:\n        # Extract date parts from filename\n        date_parts = os.path.basename(trafic_file_path).split(\".\")[0]\n        parsed_date = datetime.strptime(date_parts.replace('H', ':').replace('m', ''), \"%Y-%m-%dT%H:%M\")\n        iso_date = parsed_date.strftime(\"%Y-%m-%dT%H:%M\")\n        with open(trafic_file_path, 'r', encoding=\"windows-1252\") as file:\n            for line in file:\n                lect_linea = line.split(\";\")",
        "detail": "trafico.test5",
        "documentation": {}
    },
    {
        "label": "parse_geo_point",
        "kind": 2,
        "importPath": "trafico.test5",
        "description": "trafico.test5",
        "peekOfCode": "def parse_geo_point(geo_point):\n    \"\"\"Parse the geographical point from the string.\"\"\"\n    if \",\" in geo_point:\n        latitude, longitude = map(str.strip, geo_point.split(\",\"))\n        return float(latitude), float(longitude)\n    else:\n        logging.warning(f\"Invalid geo_point_2d value: {geo_point}\")\n        return None, None\ndef upsert_document(document):\n    \"\"\"Insert or update a document in MongoDB.\"\"\"",
        "detail": "trafico.test5",
        "documentation": {}
    },
    {
        "label": "upsert_document",
        "kind": 2,
        "importPath": "trafico.test5",
        "description": "trafico.test5",
        "peekOfCode": "def upsert_document(document):\n    \"\"\"Insert or update a document in MongoDB.\"\"\"\n    try:\n        result = db.trafico.update_one(\n            {\"id_tramo\": document[\"id_tramo\"]},\n            {\"$push\": {\"valores\": document[\"valores\"][0]}},\n            upsert=True\n        )\n        if result.upserted_id:\n            logging.info(f\"A new document has been created with id_tramo: {document['id_tramo']}\")",
        "detail": "trafico.test5",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.test5",
        "description": "trafico.test5",
        "peekOfCode": "def extractdata():\n    \"\"\"Extract data from files and process them.\"\"\"\n    path = \"/home/vagrant/Documents/bigdata/data\"\n    df_trafic_path = os.path.join(path, 'trafico')\n    if not os.listdir(df_trafic_path):\n        logging.error(\"ERROR: No traffic data files in folder available\")\n        return\n    logging.info(f'Number of files in directory: {len(os.listdir(df_trafic_path))}')\n    for file_name in os.listdir(df_trafic_path):\n        trafic_file_path = os.path.join(df_trafic_path, file_name)",
        "detail": "trafico.test5",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "trafico.test5",
        "description": "trafico.test5",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef process_file(trafic_file_path):\n    \"\"\"Process a single traffic data file.\"\"\"\n    try:\n        # Extract date parts from filename\n        date_parts = os.path.basename(trafic_file_path).split(\".\")[0]\n        parsed_date = datetime.strptime(date_parts.replace('H', ':').replace('m', ''), \"%Y-%m-%dT%H:%M\")\n        iso_date = parsed_date.strftime(\"%Y-%m-%dT%H:%M\")\n        with open(trafic_file_path, 'r', encoding=\"windows-1252\") as file:",
        "detail": "trafico.test5",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "trafico.test5",
        "description": "trafico.test5",
        "peekOfCode": "db = client.bigdata\ndef process_file(trafic_file_path):\n    \"\"\"Process a single traffic data file.\"\"\"\n    try:\n        # Extract date parts from filename\n        date_parts = os.path.basename(trafic_file_path).split(\".\")[0]\n        parsed_date = datetime.strptime(date_parts.replace('H', ':').replace('m', ''), \"%Y-%m-%dT%H:%M\")\n        iso_date = parsed_date.strftime(\"%Y-%m-%dT%H:%M\")\n        with open(trafic_file_path, 'r', encoding=\"windows-1252\") as file:\n            for line in file:",
        "detail": "trafico.test5",
        "documentation": {}
    },
    {
        "label": "log_definition",
        "kind": 2,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "def log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger\")\n    logger.setLevel(logging.INFO)  # Use DEBUG for more verbose logging",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\ndef extractdata(logger):",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "def extractdata(logger):\n    # Set the paths for your data directories\n    path = \"./data/test\"\n    trafic_folder_name = 'trafico'\n    df_trafic_path = os.path.join(path, trafic_folder_name)\n    # Check if the traffic directory contains any files\n    if not os.path.exists(df_trafic_path):\n        logger.error(f\"ERROR: Path '{df_trafic_path}' does not exist.\")\n        return\n    elif not os.listdir(df_trafic_path):",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "def main():\n    # Initialize the logger\n    logger, logs_directory, _ = log_definition()\n    # Run data extraction\n    extractdata(logger)\n    # Retrieve logs\n    get_logs(logs_directory)\nmain()",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "#client",
        "kind": 5,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up a specific logger for the application",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "trafico.test6",
        "description": "trafico.test6",
        "peekOfCode": "db = client.bigdata\ndef log_definition():\n    # Define the absolute path for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    # Verify if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Set up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger\")",
        "detail": "trafico.test6",
        "documentation": {}
    },
    {
        "label": "log_definition",
        "kind": 2,
        "importPath": "cambio_base",
        "description": "cambio_base",
        "peekOfCode": "def log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafico_logger_cambio_coordenadas.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger_cambio_coordenadas\")\n    logger.setLevel(logging.INFO)  # Use DEBUG for more verbose logging",
        "detail": "cambio_base",
        "documentation": {}
    },
    {
        "label": "get_logs",
        "kind": 2,
        "importPath": "cambio_base",
        "description": "cambio_base",
        "peekOfCode": "def get_logs(logs_directory):\n    log_file_path = os.path.join(logs_directory, 'trafic_log.log')\n    if not os.path.exists(log_file_path):\n        print(\"Log file does not exist.\")\n        return\n    with open(log_file_path, 'r') as file:\n        logs_content = file.read()\n        print(\"Log file content:\")\n        print(logs_content)\ncollection = db.trafico",
        "detail": "cambio_base",
        "documentation": {}
    },
    {
        "label": "#client",
        "kind": 5,
        "importPath": "cambio_base",
        "description": "cambio_base",
        "peekOfCode": "#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\nclient = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafico_logger_cambio_coordenadas.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)",
        "detail": "cambio_base",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "cambio_base",
        "description": "cambio_base",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafico_logger_cambio_coordenadas.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application",
        "detail": "cambio_base",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "cambio_base",
        "description": "cambio_base",
        "peekOfCode": "db = client.bigdata\ndef log_definition():\n    # The absolute path definition for the log directory\n    logs_directory = \"trafico/logs\"\n    log_file_path = os.path.join(logs_directory, 'trafico_logger_cambio_coordenadas.log')\n    # Checking if this directory exists\n    if not os.path.exists(logs_directory):\n        os.makedirs(logs_directory)\n    # Setting up a specific logger for the application\n    logger = logging.getLogger(\"trafic_logger_cambio_coordenadas\")",
        "detail": "cambio_base",
        "documentation": {}
    },
    {
        "label": "collection",
        "kind": 5,
        "importPath": "cambio_base",
        "description": "cambio_base",
        "peekOfCode": "collection = db.trafico\n# Iterar sobre cada documento y cambiar el orden de latitud y longitud\nfor doc in collection.find():\n    print(f\"Documento original: {doc}\")  # Imprimir el documento completo para ver la estructura\n    # Verificar que 'coordenadas' es una lista de dos elementos\n    if 'coordenadas' in doc and isinstance(doc['coordenadas'], list) and len(doc['coordenadas']) == 2:\n        # Extraer los valores actuales\n        latitude, longitude = doc['coordenadas']\n        # Cambiar el orden a [longitude, latitude]\n        new_coords = [longitude, latitude]",
        "detail": "cambio_base",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "connection_test",
        "description": "connection_test",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/admin')\n#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\ndb = client.Test\ncoleccion = db.list_collections_names()\nprint(coleccion)\ndoc = coleccion.find()\nfor document in doc:\n    print(document)\n#update a documento alrady created and if this documento does not exist create it\n                             result = db.trafico.update_one({\"id_tramo\":id_tramo},{\"$push\":{\"valores\":{\"fecha\":date_parts},",
        "detail": "connection_test",
        "documentation": {}
    },
    {
        "label": "#client",
        "kind": 5,
        "importPath": "connection_test",
        "description": "connection_test",
        "peekOfCode": "#client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata')\ndb = client.Test\ncoleccion = db.list_collections_names()\nprint(coleccion)\ndoc = coleccion.find()\nfor document in doc:\n    print(document)\n#update a documento alrady created and if this documento does not exist create it\n                             result = db.trafico.update_one({\"id_tramo\":id_tramo},{\"$push\":{\"valores\":{\"fecha\":date_parts},\n                                                                                   \"lectura\":lectura}})",
        "detail": "connection_test",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "connection_test",
        "description": "connection_test",
        "peekOfCode": "db = client.Test\ncoleccion = db.list_collections_names()\nprint(coleccion)\ndoc = coleccion.find()\nfor document in doc:\n    print(document)\n#update a documento alrady created and if this documento does not exist create it\n                             result = db.trafico.update_one({\"id_tramo\":id_tramo},{\"$push\":{\"valores\":{\"fecha\":date_parts},\n                                                                                   \"lectura\":lectura}})\n                            if result.raw_result[\"nModified\"] == 0:",
        "detail": "connection_test",
        "documentation": {}
    },
    {
        "label": "coleccion",
        "kind": 5,
        "importPath": "connection_test",
        "description": "connection_test",
        "peekOfCode": "coleccion = db.list_collections_names()\nprint(coleccion)\ndoc = coleccion.find()\nfor document in doc:\n    print(document)\n#update a documento alrady created and if this documento does not exist create it\n                             result = db.trafico.update_one({\"id_tramo\":id_tramo},{\"$push\":{\"valores\":{\"fecha\":date_parts},\n                                                                                   \"lectura\":lectura}})\n                            if result.raw_result[\"nModified\"] == 0:\n                                db.trafico.insert_one({\"id_tramo\":id_tramo,",
        "detail": "connection_test",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 5,
        "importPath": "connection_test",
        "description": "connection_test",
        "peekOfCode": "doc = coleccion.find()\nfor document in doc:\n    print(document)\n#update a documento alrady created and if this documento does not exist create it\n                             result = db.trafico.update_one({\"id_tramo\":id_tramo},{\"$push\":{\"valores\":{\"fecha\":date_parts},\n                                                                                   \"lectura\":lectura}})\n                            if result.raw_result[\"nModified\"] == 0:\n                                db.trafico.insert_one({\"id_tramo\":id_tramo,\n                                                       \"direccion\":direccion,\n                                                        \"coordenadas\":[latitude,longitude],",
        "detail": "connection_test",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n# 1. Count the number of traffic sections\nnumber_of_traffic_sections = db.trafico.count_documents({})\nprint(number_of_traffic_sections)\n# 2. Calculate the monthly average traffic intensity for each section\nstep1_p2 = {\n    \"$group\": {\n        \"_id\": {\n            \"id_tramo\": \"$id_tramo\",  # Group by section id",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "db = client.bigdata\n# 1. Count the number of traffic sections\nnumber_of_traffic_sections = db.trafico.count_documents({})\nprint(number_of_traffic_sections)\n# 2. Calculate the monthly average traffic intensity for each section\nstep1_p2 = {\n    \"$group\": {\n        \"_id\": {\n            \"id_tramo\": \"$id_tramo\",  # Group by section id\n            \"month\": {\"$month\": \"$valores.fecha\"}  # Extract month from the date",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "number_of_traffic_sections",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "number_of_traffic_sections = db.trafico.count_documents({})\nprint(number_of_traffic_sections)\n# 2. Calculate the monthly average traffic intensity for each section\nstep1_p2 = {\n    \"$group\": {\n        \"_id\": {\n            \"id_tramo\": \"$id_tramo\",  # Group by section id\n            \"month\": {\"$month\": \"$valores.fecha\"}  # Extract month from the date\n        },\n        \"media\": {\"$avg\": \"$valores.lectura\"}  # Calculate the average of readings",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "step1_p2",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "step1_p2 = {\n    \"$group\": {\n        \"_id\": {\n            \"id_tramo\": \"$id_tramo\",  # Group by section id\n            \"month\": {\"$month\": \"$valores.fecha\"}  # Extract month from the date\n        },\n        \"media\": {\"$avg\": \"$valores.lectura\"}  # Calculate the average of readings\n    }\n}\nstep2_p2 = {",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "step2_p2",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "step2_p2 = {\n    \"$sort\": {\"media\": -1}  # Sort by average in descending order\n}\n# Execute the aggregation\nresult = db.trafico.aggregate([step1_p2, step2_p2])\n# Print results\nfor res in result:\n    print(f\"Tramo: {res['_id']['id_tramo']}, Month: {res['_id']['month']}, Average: {res['media']:.2f}\")\n# 3)\n\"\"\" ",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "result = db.trafico.aggregate([step1_p2, step2_p2])\n# Print results\nfor res in result:\n    print(f\"Tramo: {res['_id']['id_tramo']}, Month: {res['_id']['month']}, Average: {res['media']:.2f}\")\n# 3)\n\"\"\" \n###################################### METEO\n#Ordenar las estaciones meteorológicas por latitud de mayor a menor. \nestaciones_por_latitude = db.meteo.find().sort(\"coordenadas.0\",-1)\nfor i in estaciones_por_latitude:",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "estaciones_por_latitude",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "estaciones_por_latitude = db.meteo.find().sort(\"coordenadas.0\",-1)\nfor i in estaciones_por_latitude:\n    print(f\"Estacion : {i['nombre']}, coordenadas: {i['coordenadas']}\")\nBuscar el valor de NO2 para la Avenida de Francia para la fecha del 15 de mayo \na las 12:00:00, en la salida deben figurar únicamente el identificador de la estación,\nlas coordenadas y los valores de fecha y NO2. \npipeline = [\n    {\n        \"$unwind\": \"$valores\"  # Unwind the valores array to access individual entries\n    },",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "pipeline",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "pipeline = [\n    {\n        \"$unwind\": \"$valores\"  # Unwind the valores array to access individual entries\n    },\n    {\n        \"$match\": {\n            \"id_estacion\": \"$id_estacion\",  # Filter by station ID\n            \"$expr\": {\n                \"$and\": [\n                    {\"$eq\": [{\"$month\": \"$valores.fecha\"}, 5]},  # Month must be May",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "results",
        "kind": 5,
        "importPath": "consultas",
        "description": "consultas",
        "peekOfCode": "results = db.collection.aggregate(pipeline)\n# Print the results\nfor result in results:\n    print(result)\n \"\"\"",
        "detail": "consultas",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "consultas_meteo",
        "description": "consultas_meteo",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n################################################################\n#1)\n# agregación para limitar el arreglo 'valores' a solo un elemento en el primer documento\ndocuments = db.trafico.aggregate([\n    {\n        \"$project\": {\n            \"valores\": { \"$slice\": [\"$valores\", 1] },  # se limita el arreglo 'valores' a un solo elemento\n            \"id_tramo\":1, # Se agrega el campo '_id'",
        "detail": "consultas_meteo",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "consultas_meteo",
        "description": "consultas_meteo",
        "peekOfCode": "db = client.bigdata\n################################################################\n#1)\n# agregación para limitar el arreglo 'valores' a solo un elemento en el primer documento\ndocuments = db.trafico.aggregate([\n    {\n        \"$project\": {\n            \"valores\": { \"$slice\": [\"$valores\", 1] },  # se limita el arreglo 'valores' a un solo elemento\n            \"id_tramo\":1, # Se agrega el campo '_id'\n            \"coordenadas\":1,",
        "detail": "consultas_meteo",
        "documentation": {}
    },
    {
        "label": "documents",
        "kind": 5,
        "importPath": "consultas_meteo",
        "description": "consultas_meteo",
        "peekOfCode": "documents = db.trafico.aggregate([\n    {\n        \"$project\": {\n            \"valores\": { \"$slice\": [\"$valores\", 1] },  # se limita el arreglo 'valores' a un solo elemento\n            \"id_tramo\":1, # Se agrega el campo '_id'\n            \"coordenadas\":1,\n        }\n    },\n    {\n        \"$limit\": 1  # Se Limita los resultados a solo el primer documento",
        "detail": "consultas_meteo",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "consultas_trafico",
        "description": "consultas_trafico",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n#################################################################\n\"\"\" from bson import json_util\nmeteo_centre = db.meteo.find(\n    {\"nombre\": {\"$regex\": \"centre\", \"$options\": \"i\"}},  # Buscar que 'nombre' contenga 'centre'\n    {\"coordenadas\": 1, \"nombre\": 0}  # Incluir solo 'coordenadas' y excluir 'nombre' y '_id'\n)\n# Mostrar los resultados\nfor doc in meteo_centre:",
        "detail": "consultas_trafico",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "consultas_trafico",
        "description": "consultas_trafico",
        "peekOfCode": "db = client.bigdata\n#################################################################\n\"\"\" from bson import json_util\nmeteo_centre = db.meteo.find(\n    {\"nombre\": {\"$regex\": \"centre\", \"$options\": \"i\"}},  # Buscar que 'nombre' contenga 'centre'\n    {\"coordenadas\": 1, \"nombre\": 0}  # Incluir solo 'coordenadas' y excluir 'nombre' y '_id'\n)\n# Mostrar los resultados\nfor doc in meteo_centre:\n    print(doc)",
        "detail": "consultas_trafico",
        "documentation": {}
    },
    {
        "label": "meteo_centre",
        "kind": 5,
        "importPath": "consultas_trafico",
        "description": "consultas_trafico",
        "peekOfCode": "meteo_centre = db.meteo.find(\n    {\"nombre\": {\"$regex\": \"centre\", \"$options\": \"i\"}},  # Buscar que 'nombre' contenga 'centre'\n    {\"coordenadas\": 1, \"nombre\": 0}  # Incluir solo 'coordenadas' y excluir 'nombre' y '_id'\n)\n# Mostrar los resultados\nfor doc in meteo_centre:\n    print(doc)\n \"\"\"\n################################################################\n#1)",
        "detail": "consultas_trafico",
        "documentation": {}
    },
    {
        "label": "documents",
        "kind": 5,
        "importPath": "consultas_trafico",
        "description": "consultas_trafico",
        "peekOfCode": "documents = db.trafico.aggregate([\n    {\n        \"$project\": {\n            \"valores\": { \"$slice\": [\"$valores\", 1] },  # se limita el arreglo 'valores' a un solo elemento\n            \"id_tramo\":1, # Se agrega el campo '_id'\n            \"coordenadas\":1,\n        }\n    },\n    {\n        \"$limit\": 1  # Se Limita los resultados a solo el primer documento",
        "detail": "consultas_trafico",
        "documentation": {}
    },
    {
        "label": "arrays",
        "kind": 5,
        "importPath": "consultas_trafico",
        "description": "consultas_trafico",
        "peekOfCode": "arrays = db.trafico_test.find({\"valores.fecha\": {\"$type\": \"array\"}})\nfor i in arrays:\n    print(i)\n# Filtro lo documentos donde `valores.fecha` no es de tipo `Date`\n    non_date_records = db.trafico_test.find({\"valores.fecha\": {\"$not\": {\"$type\": \"date\"}}})\n    for record in non_date_records:\n        print(record) \"\"\"\n################################################################\n################################################################\n#2.1.1)",
        "detail": "consultas_trafico",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "consultas_trafico_test",
        "description": "consultas_trafico_test",
        "peekOfCode": "client = mc('mongodb://vagrant:vagrant@localhost:27017/bigdata?authSource=admin')\ndb = client.bigdata\n#2.4)\n# Paso 0 se crea un indice espacial para poder usar latitud y longitud del campo coordenadas \n#db.trafico.find_one({},{\"valores.fecha\":{\"$slice\":1}})\n#db.trafico.drop_index(\"coordenadas_2dsphere\")\n#para consultas en terminal se usa lo siguiente db.trafico.create_index({\"coordenadas\":\"2dsphere\"})\n#db.trafico.create_index([(\"coordenadas\",\"2dsphere\")])\n# nombre del indice \"coordenadas_1_2dsphere_1\"\n# coordenadas de la estación meteorológica Centre. \"Centre\": [39.470718, -0.376384",
        "detail": "consultas_trafico_test",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "consultas_trafico_test",
        "description": "consultas_trafico_test",
        "peekOfCode": "db = client.bigdata\n#2.4)\n# Paso 0 se crea un indice espacial para poder usar latitud y longitud del campo coordenadas \n#db.trafico.find_one({},{\"valores.fecha\":{\"$slice\":1}})\n#db.trafico.drop_index(\"coordenadas_2dsphere\")\n#para consultas en terminal se usa lo siguiente db.trafico.create_index({\"coordenadas\":\"2dsphere\"})\n#db.trafico.create_index([(\"coordenadas\",\"2dsphere\")])\n# nombre del indice \"coordenadas_1_2dsphere_1\"\n# coordenadas de la estación meteorológica Centre. \"Centre\": [39.470718, -0.376384\ntry:",
        "detail": "consultas_trafico_test",
        "documentation": {}
    },
    {
        "label": "extractdata",
        "kind": 2,
        "importPath": "format_file",
        "description": "format_file",
        "peekOfCode": "def extractdata():\n    # 1. verificaciones\n    # 1.1 verificar si tenemos documentos en el directorio de trabajo.\n    # print(\"hello world\")\n    # https://www.geeksforgeeks.org/check-if-directory-contains-file-using-python/\n    path = \"/home/vagrant/Documents/bigdata/bigdata_project/data\"\n    trafic_forlder_name = 'trafico'\n    meteo_forlder_name = 'estaciones_metereologicos'\n    meteo_path = f'{path}/{meteo_forlder_name}'\n    trafic_path = f'{path}/{trafic_forlder_name}'",
        "detail": "format_file",
        "documentation": {}
    },
    {
        "label": "result",
        "kind": 5,
        "importPath": "mongopush",
        "description": "mongopush",
        "peekOfCode": "result = db.update_one({\"id_tramo\"=id_tramo},{\"&push\":{\"valores\":{\"fecha\":fecha,\"lectura\":lectura}}})\nif result.raw_result[\"nModified\"] == 0:\n    db.insert_one({\"id_tramo\":id_tramo,\n                   \"direccion\":direccion,\n                   \"coordenadas\":coordenadas,\n                   \"valores\":diccionario})\ndiccionario = {\"fecha[:fecha,\"lectura\":]\n               \"\"\" \n                    if lectura == -1 or lectura > 5000 or group['Estat / Estado'] != 0:\n                        lectura = None",
        "detail": "mongopush",
        "documentation": {}
    },
    {
        "label": "diccionario",
        "kind": 5,
        "importPath": "mongopush",
        "description": "mongopush",
        "peekOfCode": "diccionario = {\"fecha[:fecha,\"lectura\":]\n               \"\"\" \n                    if lectura == -1 or lectura > 5000 or group['Estat / Estado'] != 0:\n                        lectura = None\n                    else:\n                        lectura = lectura\n \"\"\"",
        "detail": "mongopush",
        "documentation": {}
    }
]